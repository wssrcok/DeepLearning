{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "c8Pqt5O58m-T"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samshen/anaconda/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bX7yVwIl8sQI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cViWqKB28xA5"
   },
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Implements the sigmoid activation in numpy\n",
    "    \n",
    "    Arguments:\n",
    "    Z -- numpy array of any shape\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of sigmoid(z), same shape as Z\n",
    "    cache -- returns Z as well, useful during backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Implement the RELU function.\n",
    "    Arguments:\n",
    "    Z -- Output of the linear layer, of any shape\n",
    "    Returns:\n",
    "    A -- Post-activation parameter, of the same shape as Z\n",
    "    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache\n",
    "  \n",
    "def softmax(Z):\n",
    "    \"\"\"\n",
    "    Implement the RELU function.\n",
    "    Arguments:\n",
    "    Z -- Output of the linear layer, of any shape\n",
    "    Returns:\n",
    "    A -- Post-activation parameter, of the same shape as Z\n",
    "    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "\n",
    "    Z_exp = np.exp(Z);\n",
    "    den = np.sum(Z_exp, axis = 0);\n",
    "    A = Z_exp / den;\n",
    "\n",
    "    assert(A.shape == Z.shape)\n",
    "\n",
    "    cache = Z \n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single RELU unit.\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single SIGMOID unit.\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "  \n",
    "def softmax_backward(Y, Y_hat):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single SIGMOID unit.\n",
    "    Arguments:\n",
    "    \n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    dZ = Y_hat - Y\n",
    "    \n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "29fGpjay83hR"
   },
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "        \n",
    "    return parameters\n",
    "\n",
    "\n",
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    Z = np.dot(W,A)+b\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Svtr1Aas9Aqs"
   },
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = relu(Z)\n",
    "        ### END CODE HERE ###\n",
    "    elif activation == \"softmax\":\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = softmax(Z)\n",
    "        \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nq6F-n5a9ESE"
   },
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() (there are L-1 of them, indexed from 0 to L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], \n",
    "                                             parameters['b' + str(l)], \"relu\")\n",
    "        caches.append(cache)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], \n",
    "                                          parameters['b' + str(L)], \"softmax\")\n",
    "    caches.append(cache)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    #assert(AL.shape == (10,X.shape[1]))\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-F4EzHNSH2ur"
   },
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y, cost_function = 'softmax_cross_entropy'):\n",
    "    \"\"\"\n",
    "    Implement the cost function defined by equation (7).\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, shape (10, number of examples)\n",
    "    Y -- true \"label\" vector (for example: [1,0,0,...,0] as 0\n",
    "         [0,1,0,...,0] as 1), shape (classes, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Compute loss from aL and y.\n",
    "    ### START CODE HERE ### (≈ 1 lines of code)\n",
    "    if cost_function == 'softmax_cross_entropy':\n",
    "        cost = (-1/m) * np.sum(Y*np.log(AL))\n",
    "    elif cost_function == 'sigmoid_cross_entropy':\n",
    "        cost = -1/m*np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL))\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iv2IsSaEH_Np"
   },
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    dW = 1/m*np.dot(dZ,A_prev.T)\n",
    "    db = 1/m*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gSWAbuSbIAGd"
   },
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, Y, Y_hat, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ,linear_cache)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ,linear_cache)\n",
    "        ### END CODE HERE ###\n",
    "    elif activation == \"softmax\":\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dZ = softmax_backward(Y, Y_hat)\n",
    "        dA_prev, dW, db = linear_backward(dZ,linear_cache)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "R9Vzq9C0ICTt"
   },
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
    "    \n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"dAL, current_cache\". Outputs: \"grads[\"dAL-1\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    current_cache = caches[L-1]\n",
    "    #grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, 'sigmoid')\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, Y, AL, 'softmax')\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Loop from l=L-2 to l=0\n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        # Inputs: \"grads[\"dA\" + str(l + 1)], current_cache\". Outputs: \"grads[\"dA\" + str(l)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n",
    "        ### START CODE HERE ### (approx. 5 lines)\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l+1)], current_cache, Y, AL, 'relu')\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eqcK9yeUIFZ1"
   },
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] -= learning_rate * grads['dW'+str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] -= learning_rate * grads['db'+str(l+1)]\n",
    "    ### END CODE HERE ###\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "C0veWoz3P5XJ"
   },
   "outputs": [],
   "source": [
    "def one_hot_label(classes, label):\n",
    "    \"\"\"\n",
    "    reshape label to Sam prefered shape for mnist\n",
    "\n",
    "    Arguments:\n",
    "    label -- input label with shape (m,)\n",
    "\n",
    "    Returns:\n",
    "    new_label -- output label with shape (10, 1, m)\n",
    "    \"\"\"\n",
    "    m = label.shape[0]\n",
    "    new_label = np.zeros((classes, m))\n",
    "    for i in range(m):\n",
    "        clas = label[i]\n",
    "        new_label[clas,i] = 1\n",
    "    return new_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 1080)\n"
     ]
    }
   ],
   "source": [
    "train_data_orig, train_labels_orig, eval_data_orig, eval_labels_orig, classes = load_dataset()\n",
    "classes = 6\n",
    "train_labels = np.squeeze(train_labels_orig)\n",
    "train_labels_old = train_labels\n",
    "train_labels = one_hot_label(classes, train_labels_old)\n",
    "eval_labels = np.squeeze(eval_labels_orig)\n",
    "eval_labels_old = eval_labels\n",
    "eval_labels = one_hot_label(classes, eval_labels_old)\n",
    "# Flatten the training and test images\n",
    "train_data = train_data_orig.reshape(train_data_orig.shape[0], -1).T\n",
    "eval_data = eval_data_orig.reshape(eval_data_orig.shape[0], -1).T\n",
    "# Normalize image vectors\n",
    "train_data = train_data/255.\n",
    "eval_data = eval_data/255.\n",
    "features = train_data.shape[0]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 713
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5471,
     "status": "ok",
     "timestamp": 1524423903496,
     "user": {
      "displayName": "Sam Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100562431021972138930"
     },
     "user_tz": 420
    },
    "id": "iUnl80CzJRW3",
    "outputId": "a53edd3c-90b7-4072-be10-8deea3b77f95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "(784, 55000)\n"
     ]
    }
   ],
   "source": [
    "# Load training and eval data\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images.T # Returns np.array\n",
    "classes = 10\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "train_labels = one_hot_label(classes, train_labels)\n",
    "eval_data = mnist.test.images.T # Returns np.array\n",
    "eval_labels_old = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "eval_labels = one_hot_label(classes, eval_labels_old)\n",
    "features = train_data.shape[0]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1524423903884,
     "user": {
      "displayName": "Sam Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100562431021972138930"
     },
     "user_tz": 420
    },
    "id": "sfod1faNVngV",
    "outputId": "e7a6c559-a8c9-47f3-a6e7-157625017986"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 55000)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KYtvwudOKHk0"
   },
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, parameters = {}, batch_size = 64, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    #np.random.seed(1)\n",
    "    costs = []                         # keep track of cost\n",
    "    \n",
    "    # Parameters initialization. (≈ 1 line of code)\n",
    "    if len(parameters) == 0:\n",
    "        parameters = initialize_parameters_deep(layers_dims)\n",
    "    m = X.shape[1]\n",
    "    num_batchs = m // batch_size\n",
    "    \n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "        for j in range(num_batchs):\n",
    "            # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "            # AL is the output and caches contains Z, A, W, b for each layer\n",
    "            AL, caches = L_model_forward(X[:, j*batch_size:(j+1)*batch_size], parameters)\n",
    "            # Compute cost.\n",
    "            cost = compute_cost(AL,Y[:, j*batch_size:(j+1)*batch_size])\n",
    "            # Backward propagation.\n",
    "            grads = L_model_backward(AL, Y[:, j*batch_size:(j+1)*batch_size], caches)\n",
    "            # Update parameters.\n",
    "            parameters = update_parameters(parameters, grads, learning_rate)\n",
    "            # Print the cost every 30 training example\n",
    "            if print_cost and j % 1 == 0:\n",
    "                print (\"Cost after iteration %i, batch %i: %f\" %(i, j, cost))\n",
    "            if print_cost and j % 5 == 0:\n",
    "                costs.append(cost)\n",
    "        if print_cost and i % 1 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "#         if print_cost and i % 5 == 0:\n",
    "#             costs.append(cost)\n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 1080)\n",
      "(6, 1080)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 988
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 162839,
     "status": "ok",
     "timestamp": 1524424075781,
     "user": {
      "displayName": "Sam Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100562431021972138930"
     },
     "user_tz": 420
    },
    "id": "AZlK7EE4crMa",
    "outputId": "c6a279bb-a9e3-4e9e-afa6-fed4d8bfd9ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0, batch 0: 1.791746\n",
      "Cost after iteration 0, batch 1: 1.791700\n",
      "Cost after iteration 0: 1.791700\n",
      "Cost after iteration 1, batch 0: 1.791734\n",
      "Cost after iteration 1, batch 1: 1.791695\n",
      "Cost after iteration 1: 1.791695\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-829fc8b427a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# training model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlayers_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#  2-layer model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL_layer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-9f2ec3738758>\u001b[0m in \u001b[0;36mL_layer_model\u001b[0;34m(X, Y, layers_dims, parameters, batch_size, learning_rate, num_iterations, print_cost)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL_model_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# Update parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;31m# Print the cost every 30 training example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-601c16a13afe>\u001b[0m in \u001b[0;36mupdate_parameters\u001b[0;34m(parameters, grads, learning_rate)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m### START CODE HERE ### (≈ 3 lines of code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dW'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'db'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training model\n",
    "layers_dims = [features, 4096, 4096, 12, classes] #  2-layer model\n",
    "parameters = L_layer_model(train_data, train_labels, layers_dims, batch_size = 512, learning_rate = 0.01, num_iterations = 5, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 988
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 162655,
     "status": "ok",
     "timestamp": 1524424291554,
     "user": {
      "displayName": "Sam Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100562431021972138930"
     },
     "user_tz": 420
    },
    "id": "XMFB3PxjKQ4t",
    "outputId": "e2ebca9c-8be3-409c-8db5-139e8ebca265"
   },
   "outputs": [],
   "source": [
    "# further training on the same model \n",
    "parameters = L_layer_model(train_data, train_labels, layers_dims, batch_size = 512, parameters = parameters, learning_rate = 0.5, num_iterations = 5, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-f-nnqz-mfGo"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XW8NLZ5_Plcc"
   },
   "outputs": [],
   "source": [
    "def eval_model(X, y, parameters):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  L-layer neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((y.shape[0],m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(probas.shape[0]):\n",
    "        for j in range(probas.shape[1]):\n",
    "            if probas[i,j] == np.max(probas[:,j]):\n",
    "                p[i,j] = 1\n",
    "            else:\n",
    "                p[i,j] = 0\n",
    "    \n",
    "    #print results\n",
    "    #print (\"predictions: \" + str(probas))\n",
    "    #print (\"predictions: \" + str(p))\n",
    "    #print (\"true labels: \" + str(y))\n",
    "    match = 0\n",
    "    for i in range(m):\n",
    "        match += int(np.array_equal(p[:,i],y[:,i]))\n",
    "    print(\"Accuracy: \"  + str(np.sum(match*1.0/m)))\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_vT032p2Pm0A"
   },
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  L-layer neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(probas.shape[0]):\n",
    "        for j in range(probas.shape[1]):\n",
    "            if probas[i,j] == np.max(probas[:,j]):\n",
    "                p[0,j] = i\n",
    "    \n",
    "    #print results\n",
    "    #print (\"predictions: \" + str(probas))\n",
    "    print (\"predictions: \" + str(int(np.squeeze(p))))\n",
    "    #print (\"true labels: \" + str(y))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7999,
     "status": "ok",
     "timestamp": 1524424305787,
     "user": {
      "displayName": "Sam Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100562431021972138930"
     },
     "user_tz": 420
    },
    "id": "ebpt464ANpnK",
    "outputId": "bd7bfa51-50bf-4ec5-c689-cf40424bcb8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7388888888888889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 0., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        1., 0., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(train_data, train_labels, parameters)\n",
    "eval_model(eval_data, eval_labels, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1524205134652,
     "user": {
      "displayName": "Sam Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100562431021972138930"
     },
     "user_tz": 420
    },
    "id": "zGyOlEriv4lf",
    "outputId": "0af28b55-b550-4f3e-e2e2-f145ba7d74a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: 4\n",
      "actual value: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1856dbc828>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_num = 61\n",
    "predict(eval_data[:,image_num:image_num+1],parameters)\n",
    "#print(\"actual value: \" + str(eval_labels_old[image_num]))\n",
    "print(\"actual value: \" + str(np.squeeze(train_labels_orig[:, image_num])))\n",
    "#data = mnist.test.images[image_num].reshape(28,28)\n",
    "data = train_data_orig[image_num]\n",
    "plt.imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Ew1O8bo7v4lg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "cnn_mnist.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
